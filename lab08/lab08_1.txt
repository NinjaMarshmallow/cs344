Exercise 8.1

a) Task 1

        The minimum is much lower than maximum, so the data may be sparse, resulting is worse fitting to the data. 
        Median income does not specify a curreny and goes from 0.5 to 15, which isn't clear what that means. There seems to be very few bedrooms compared to the population.
    
    Task 2

        The set of 17000 data points was in order of geographical location. So the Validation had the Northwest portion and the training contained the Southeast portion.
        So the validation set in not representative of the training set and vice versa.
    
    Task 3
        To fix this the data must be randomized to make both sets similar in shape
        When splitting training and validation, you cannot use a sorted dataframe

    Task 4
  
        # Create input functions.
        training_input_fn = lambda: my_input_fn(
            training_examples, 
            training_targets["median_house_value"], 
            batch_size=batch_size)
        predict_training_input_fn = lambda: my_input_fn(
            training_examples, 
            training_targets["median_house_value"], 
            num_epochs=1, 
            shuffle=False)
        predict_validation_input_fn = lambda: my_input_fn(
            validation_examples, validation_targets["median_house_value"], 
            num_epochs=1, 
            shuffle=False)

        validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)
        validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])

        I was honestly completely lost at this point, so after a good while I used the solution completely

    Task 5

        Still very lost. The website doesn't give any decent hints at what it wants you to do.

        california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")

        test_examples = preprocess_features(california_housing_test_data)
        test_targets = preprocess_targets(california_housing_test_data)

        predict_test_input_fn = lambda: my_input_fn(
            test_examples, 
            test_targets["median_house_value"], 
            num_epochs=1, 
            shuffle=False)

        test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)
        test_predictions = np.array([item['predictions'][0] for item in test_predictions])

        root_mean_squared_error = math.sqrt(
            metrics.mean_squared_error(test_predictions, test_targets))

        print("Final RMSE (on test data): %0.2f" % root_mean_squared_error)

b)

    When using ML to train a predictor, you need a large dataset that has been randomized.
    You need to split that dataset into about 70% Training examples and 30% Validation tests
    You need to ensure that they are relatively similar in shape.
    After training, you need a completely new, but similar dataset (perhaps a different year), 
        to see if the model overfits the training examples.
    Once it passes the testing and is not overfitted, it will work as a predictive model